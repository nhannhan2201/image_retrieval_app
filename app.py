import os
import streamlit as st
import pandas as pd
import faiss
from PIL import Image

from utils.retrieval import load_model, query_images
from utils.ocr_search import search_ocr

# --------------------------------------------
# ‚öôÔ∏è C·∫•u h√¨nh trang
# --------------------------------------------
st.set_page_config(page_title="üé• Video Retrieval Demo", layout="wide")

# --------------------------------------------
# üß† Load m√¥ h√¨nh & d·ªØ li·ªáu
# --------------------------------------------
@st.cache_resource
def load_model_faiss():
    """Load CLIP model v√† FAISS index (cache theo session)"""
    model, tokenizer, _ = load_model()
    index = faiss.read_index("data/merged_index.index")
    return model, tokenizer, index

@st.cache_data
def load_metadata():
    """Load metadata (c√°c th√¥ng tin ·∫£nh)"""
    return pd.read_csv("data/metadata.csv")

@st.cache_data
def load_ocr_data():
    """Load d·ªØ li·ªáu OCR"""
    return pd.read_csv("data/ocr_data.csv")

# Load t·∫•t c·∫£ d·ªØ li·ªáu c·∫ßn thi·∫øt
model, tokenizer, index = load_model_faiss()
meta_df = load_metadata()
ocr_df = load_ocr_data()

# --------------------------------------------
# üñºÔ∏è Giao di·ªán ch√≠nh
# --------------------------------------------
st.title("üé• Video Retrieval Demo")
st.write("T√¨m ki·∫øm keyframe trong video b·∫±ng **CLIP (Visual)** ho·∫∑c **OCR text similarity (Text)**")

mode = st.radio("üîç Ch·ªçn ph∆∞∆°ng th·ª©c t√¨m ki·∫øm:", ["Visual Search (CLIP)", "OCR Search (Text)"])
query = st.text_input("Nh·∫≠p truy v·∫•n:", "ng∆∞·ªùi ƒë√†n √¥ng ƒëang ph√°t bi·ªÉu")
top_k = st.slider("S·ªë l∆∞·ª£ng k·∫øt qu·∫£ hi·ªÉn th·ªã:", 1, 10, 5)

# --------------------------------------------
# üöÄ Th·ª±c thi t√¨m ki·∫øm
# --------------------------------------------
if st.button("üîç T√¨m ki·∫øm"):
    if mode.startswith("Visual"):
        st.write("ƒêang truy v·∫•n b·∫±ng m√¥ h√¨nh CLIP...")
        ids, distances = query_images(model, tokenizer, index, query, top_k)
        cols = st.columns(top_k)
        for i, (idx, dist) in enumerate(zip(ids, distances)):
            if idx >= len(meta_df):
                continue
            row = meta_df.iloc[idx]
            
            # üß© X·ª≠ l√Ω ƒë∆∞·ªùng d·∫´n ·∫£nh an to√†n
            img_path = row.get("full_path", "")
            if not os.path.exists(img_path):
                # Th·ª≠ t√¨m trong th∆∞ m·ª•c keyframes
                img_path = os.path.join("data/keyframes", os.path.basename(img_path))
            
            if os.path.exists(img_path):
                img = Image.open(img_path)
                with cols[i]:
                    st.image(img, caption=f"{row.get('image_id', idx)} (score={1/(1+dist):.3f})")
            else:
                with cols[i]:
                    st.warning(f"‚ö†Ô∏è Kh√¥ng t√¨m th·∫•y ·∫£nh: {img_path}")

    else:
        st.write("ƒêang t√¨m ki·∫øm b·∫±ng OCR...")
        results = search_ocr(ocr_df, query, top_k)
        st.write("### üßæ K·∫øt qu·∫£ OCR:")
        for r in results:
            content = str(r.get("content", ""))[:120]
            st.markdown(f"**[{r.get('similarity', 0):.2f}]** ‚Üí `{content}...`")
